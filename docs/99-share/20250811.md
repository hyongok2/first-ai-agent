# 2025년 8월 11일 업무 공유

## 0. 사전 준비
- DB 데이터 및 설정 사전 준비 필요

---

## 1. 진행 사항
- **MCP Server 개발**
  - 단순 Echo 기능 구현
  - 오라클 DB 연동 기능 구현
- **MCP Server 평가용 Test AI Agent 개발**
  - 모든 요청/응답을 파일 단위로 로깅하여 분석 가능하도록 구현
  - 프롬프트를 최대한 상세하게 작성
  - 다수의 단계를 거쳐 LLM이 사용자의 요청을 해결하는 구조 구성

---

## 2. 클로드 데스크탑 시연
- 하이엔드 모델의 동작 방식 확인
- 속도 면에서는 여전히 빠르지 않음

---

## 3. 테스트 에이전트 - MCP 연결 시연
- **테스트 모델**
  - `qwen3:32b`
  - `gpt-oss:20b`
  - `gpt-oss:120b`

---

## 4. 흥미로운 점
- `gpt-oss:20b`, `gpt-oss:120b` → 파라미터가 있는 MCP 도구를 다루는 데 비교적 능숙
- 기존 모델(예: `qwen3:32b`)은 MCP 도구 사용에 어려움 존재

---

## 5. 한계점
- 전반적으로 속도가 느림
- MCP 도구 활용이 전반적으로 능숙하다고 보기 어려움
- 과도한 프롬프트 미세 튜닝 필요
  - 단계가 길어져 시간 소요 증가
- **(중요)** 근본적인 문제:
  - MCP는 **Local AI Agent** 용 설계  
  - 서버 환경에서 활용 시 구조적 제약 존재 (상세 문서 참조)

---

## 6. 가능성
- `gpt-oss:120b` → 답변 품질 우수
- 프롬프트 설계를 잘 하면 원하는 결과 도출 가능  
  (단, 속도 저하 문제 여전)

---

## 7. 전략 논의 필요
- 시스템 구성 관점에서 **근본적인 방향 설정** 필요
- 개발이 필요한 요소를 세분화하여 전략 수립
- 이번 시연 및 한계점을 바탕으로 구체적인 실행 방향 논의 필요
- H/W 스펙에 따른 한계점 고려 필수  
  (예: 다중 접속 처리 문제)
- LLM 활용과 관련된 **조직의 장기 방향성** 검토 필요
- 우리는 **어떤 가치**를 **어떤 방식**으로 제공할 수 있는지에 대한 고민이 필요함
